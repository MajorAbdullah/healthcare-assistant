Hello, and welcome to this lesson on Oracle Generative AI Agents, a part of OCI Generative AI course. As we have seen, OCI Generative AI service and RAG in the earlier lessons, we will now discuss about Oracle's Generative AI Agent service.

So let's understand what this service is all about. Generative AI Agents is a fully managed service that combines the power of large language models with an intelligent retrieval system aimed at creating contextually relevant answers by searching your knowledge base. For example, we ask this AI agent to book me a flight to Vegas as well as a room at Hilton Hotel.

The agent will understand and interpret the query, determine what next steps are to be taken, retrieves data from the data stores, and finally gives a response or executes an action. In this case, you can see that the response is your travel is booked, most likely after performing the necessary actions.

So overall, agents are applications of large language models, packaged and validated and ready to use out of the box. OCI Generative AI Agents supports several ways to onboard your data, where you and your customers can interact with your data using a chat interface or an API.

Let's talk about the overall architecture. So the journey begins with the interface. This is the point where the user interacts with the AI agent. It can be a chatbot, a web app, a voice interface, or any application where the user inputs a query or a command. The system feeds various inputs to large language model.

So first one is short/long term memory. It can provide context from past interactions, enabling continuity and relevance in conversations. Tools-- you can integrate different external tools, for example, different APIs, databases, or third-party systems to enhance the model's capabilities.

And then there is prompt. It contains the specific query or task provided by the user guiding the AI on how to generate responses. And at the heart of the system, you can see that there is large language model. It basically performs four key operations, reasoning, acting, persona, and planning.

So in reasoning, it analyzes the input to generate logical and coherent responses. For acting, it determines actions based on the task, for example, whether it's about querying databases or calling different APIs. Persona is maintaining a consistent tone, style, and behavior aligned with the brand or use case. And fourth, planning, that is strategically organizing responses or actions, especially in multi-step workflows.

The LLM can also access external knowledge bases, such as databases or document repositories, to enrich its responses with accurate and up-to-date information. You have already seen a use case of RAG. This allows the agent to go beyond just its internal training data.

And based on all the processed inputs, reasoning, and integrated knowledge, the LLM generates a response. And this response is tailored to the query and context provided by the user. The output generated by the AI agent can feed back into its short term memory, enabling improved responses in ongoing interactions.

So you can say that overall, there is a feedback loop as well. And this architecture ensures that the Oracle Generative AI Agent delivers highly intelligent contextual and actionable responses by leveraging user inputs, external tools, and robust reasoning capabilities. It is designed for scalability, adaptability, and efficiency in enterprise applications. So overall, this AI agent is an LLM-based application, which can perform complex tasks on its own, mimic chain of thought process, can automate different use cases, and utilize existing data to complete actions or to provide a response.

We will now explore the core concepts that empowered the agents to deliver intelligent and, again, contextually relevant interactions. At the heart of OCI Generative Agents lies the generative AI model. This is a large language model, as we saw earlier in the architecture.

It is trained on vast data sets to generate human-like text. It processes, new inputs to produce again coherent and contextually appropriate responses, enabling natural language understanding and generation.

Next one is the agent itself. This is an autonomous system built upon the LLM. It comprehends and generates text while facilitating natural language interactions. OCI supports RAG agents which connect to data sources, retrieve pertinent information, and enhance model responses with this data, which ensures more accurate and relevant outputs.

When using RAG agents, models need to perform with high answerability and groundedness. So answerability is where the model can generate relevant responses to different user queries. And groundedness, on the other hand, is that the model-generated responses should be tracked to different data sources.

To function effectively, an agent accesses data through a structured hierarchy. And the first one is data source, then data store, and the other one is knowledge base. So let's discuss about the data store first. The repository where data resides, such as object storage buckets or databases. That is what we call as data store.

The data source, it provides connection details to the data store, enabling the agent to access and retrieve data. And the knowledge base is basically the vector storage system that ingests data from the data source, organizing it for efficient retrieval and use by the agent. And this structure ensures that agents can seamlessly access and utilize the necessary information to generate informed responses.

Again, Oracle provides multiple data options to make your information accessible to generative AI agents. The first one is object storage data. You can directly upload data files to OCI Object Storage, allowing the service to automatically ingest the data. And again, this is a service managed option. That means the service takes care of this ingestion part.

Second one is OpenSearch data, where you can bring your own ingested and indexed data from OCI Search with OpenSearch for the agents to utilize. And the third one is Oracle Database vector store. You can again bring your own vector embeddings from an Oracle Base Database 23ai or an Autonomous Database 23ai vector store to the generative AI agents.

In this course, we will discuss about the object storage and Oracle Database 23ai options. As we earlier discussed, this data ingestion is the process of extracting data from source documents, transforming it into a structured format suitable for analysis and storing it within the knowledge base. This step is crucial for preparing the raw data so that the agent can efficiently access and utilize it during interactions.

Let's continue to some more concepts. The first one is session. A session represents the interactive conversation initiated by a user, maintaining context throughout the exchange to ensure coherent and relevant responses.

The second one is agent endpoint. It is a specific access point that enables the agent to communicate with external systems or services. It also facilitates the exchange of data, allowing the agent to retrieve or send information as needed to perform its functions effectively.

There is a feature called trace. This tracks and displays the history of a chat conversation, including both user prompts and the agent's responses. This functionality is valuable for monitoring interactions, understanding decision making process, and ensuring transparency in the agent's operations.

On the other hand, citation refers to the source of information used in the agent's response. The RAG agent provides citations for each response, including details like title, external path, document ID, and page numbers. And this ensures that users can trace responses back to their original source, enhancing trust and accountability.

The last one is content moderation. So it is a feature designed to detect and filter out harmful content from both user prompts and generated responses. It focuses on identifying and mitigating various types of harm, including hate and harassment, self-inflicted harm, ideological harm, and exploitation, ensuring that interactions remain safe and respectful. Keep in mind, moderation can be applied to just user prompt or generated response, or to both.

We already know that we upload data files to OCI Object Storage and let Generative AI agents automatically ingest the data. Now, we will see some guidelines on using object storage as data source.

So you can, again, as I mentioned, upload your data as files to an object storage bucket. Each data source is associated with a single bucket. Keep in mind again, only one bucket allowed per data source. The service supports only PDF and text file formats, and each file must not exceed 100 MB in size. The PDF files can include images, charts, and reference tables, but these elements again must not exceed 8 MBA.

Moving on, you have to ensure that charts are two dimensional with labeled axes. The model can interpret and answer questions about these charts without any additional preparation. You can also use reference tables with several rows and columns. The agent can read and interpret such tables effectively.

All hyperlinks present in the PDF documents are extracted and displayed as clickable links in the chat responses. And if your data is not ready yet, you can always create an empty folder for the data source and populate it later. This approach basically allows you to set up the data source in advance and ingest data once it's available. By following these object storage guidelines, you can ensure that your data is properly prepared and accessible for Oracle's Generative AI agents, leading to more effective and efficient AI-driven interactions.

We just discussed object storage guidelines. Let's now discuss Oracle Database guidelines with respect to the Generative AI agents. Generative AI agents does not manage the database, so you must set up your existing database so Generative AI agents can connect to it.

You need to create an Oracle Database 23ai table as seen here with the fields such as DOCID, body, and vector. There are optional fields as well, such as CHUNKID, URL, title, and page numbers. Again here, you have the body, which are the chunks of the data, and the text vector, which is the vector generated from the body using an embedding model.

Next, you will need to set up a database function that can return vector search results from each query. A function is a subprogram that can take parameters and returns a value. For the required input, you have parameters such as p_query and top_k. So you can see here the name of the function is retrieval_func_ai. And the two parameters which we pass in this function are p_query and top_k.

There are some additional requirements too. You must ensure that the embedding model used for the function's query field matches the embedding model that transformed the database table's body content into vector embeddings. This means the embedding model used in the query, which is Cohere embed multilingual v3 must match the embedding model used to generate the text_vec column in the database which we just saw.

The functions return field must align with the table's required field, which were DOCID, body, and score. If the function's return field names differ from the table field names, you can use aliases within the function. For example, here you have used score as an alias for this calculation.

So let's see what's happening in this code block. The query accesses a table, which contains vector embeddings. This table also includes the columns such as DOCID, body, and text_vector. The body is the original text content of the document, and text_vec is nothing but the pre-computed vector embeddings of the document content. It then calculates vector distance using cosine similarity or Euclidean distance.

And this vector distance is the distance between the query vector and the document embeddings, which is text vector. The query then retrieves the top_k rows sorted by the similarity score in descending order. This ensures the most relevant results are returned to the user. So now, this function returns a SYS_REFCURSOR with the following fields and the fields where DOCID, body, and score. And you can see it returned v_results here and which is used as SYS_REFCURSOR here.

Now, since you are familiar with the guidelines, let's quickly look at the different concepts which we saw earlier and try to understand the overall workflow of creating an agent. So you start with the knowledge base. So this is a knowledge base using object storage as data store. You can see here different objects in the buckets defined as data source for this knowledge base.

So once you have provided the name, compartment, and other necessary information, you choose the data store type. You can enable hybrid search, which is, again, a combination of lexical as well as semantic search. And then you specify your data source. And the data is stored in this particular bucket.

You can see there are two objects here. One is text file, another is PDF file. You will click on Create and then go back. You can again either choose to start the ingestion job right away or you can manually create it later. So this is the first step, which is creating a knowledge base.

Moving on, you can also create a knowledge base for Oracle 23ai. So you again have to provide name, compartment, and other necessary information. In the data store type, you can choose Oracle AI vector search. Again, you set up the database tool connection. List that connection and you provide the vector search function, which we just saw earlier. And then click on Create. And this is how you create a knowledge base for Oracle 23ai.

Moving on, the next step is to create an agent. Again, you will provide some necessary information, then welcome message and instructions for RAG generation if any. Then you will choose one of the knowledge base created earlier. So you can either choose the Oracle 23ai or you can choose the object storage knowledge base.

Once the agent is created, you can create an endpoint, which is a specific access point that enables the agent to communicate with external systems or different services. Again, you can see different fields and parameters. We discussed session moderation, trace and citation already, so you can choose to select those and apply or not. Then you will click on Create.

Moving on, the next step is the chat. So here, you finally chat with the agent using the agent endpoint, which you just created. And here, you can see the citations and trace. Again, citations are the groundedness or where your information is getting retrieved from. And traces is just maintaining the query as well as the responses.

So we will further see all of these steps individually in the upcoming lessons. So in case if you are not clear about something, no need to worry. We have two demos, one on object storage knowledge base and other one is on Oracle Database 23ai of knowledge base.

Finally, the one last thing to keep in mind is default resource limits. So you can see different resources listed out here. And you can see their respective default limits here. Keep in mind, you can always raise a request to change.

So this concludes our topic. So we saw the overview and architecture of OCI Generative AI Agents. We discussed about different agents concepts. We also discussed about object storage and Oracle Database guidelines.