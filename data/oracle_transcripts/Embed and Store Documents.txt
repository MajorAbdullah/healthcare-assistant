In the previous lesson, we discussed how documents are loaded and split into chunks. Now let us see how chunks are embedded and stored for retrieval. But before that, let us understand what are embeddings.

If we take an example of three group of words, say animals, fruits and places and are given a word tiger. We as human beings will place it in the animals group because we know that semantically, tiger is similar to the words in the animal group. But for the machines to understand the similarity of words or sentences or even documents, concept of embeddings was born.

The embeddings of similar words or sentences or documents are close by in the multidimensional space. This is achieved through a process of training the embedding building models. One string embeddings reflects semantic similarity of words or sentences or documents.

What we see in the picture is a two dimensional representation of the embeddings of a few words. If we measure the similarity of a new word, say tiger with the other words, it would be closer to the words in the animals group than the words in the fruits or places group.

Here we see four words and their corresponding numerical representations. Embeddings of the semantically similar words are close by. We can also have embeddings for sentences, paragraphs, or even documents, which can be used to compare semantic similarity.

Now that we understand what embeddings are, let us see how we can generate embeddings from the chunks. Embeddings are created using train embedding model. Oracle 23ai supports using embedding model inside or outside the database. For generating embeddings outside the database, third party embedding models can be used.

If you want to keep the data within the database itself, then we can import ONNX that is ONNX format embedding models in a database 23ai and embed the chunks within the database itself. Now that we know how embeddings are created, let us see how we can store them.

Oracle 23ai introduced a new data type vector to store embeddings in a database column. So we can create a column of type vector data type along with the columns of other data types, while creating a database table and store embeddings into this column. We can use usual database inserts or update statements to create records that contain vector data type.

So far, we have split documents and created chunks. Now let me walk you through the code to embed chunks and store these in a Oracle 23ai vector store. For this, we need to create a database connection in the first place. We use username, password, and data source name as input parameters and pass it to Oracle DB connect method.

Once we have database connection object, we are ready to proceed further. We have created chunks earlier by splitting documents. In order to store these in a database, we need to convert these to document objects that have a page content and metadata.

For this, we iterate through chunks, extract page number, and actual text content of the chunk, and then create a dictionary using the ID, link, and text as keys. We pass in this dictionary to the chunks to Docs wrapper function. This function creates a metadata and page content and returns a document which wraps metadata and page content.

Finally, we have a list of documents which correspond to chunks we had. Now we can embed and store these. For this, we create an embedding model using OCI Generative AI service. We pass in the model name, service endpoint, compartment name, and authtype as parameters.

Finally, we create a vector store using Oracle VS class and from documents method. We pass in a list of documents that we created, embedding model, database connection, name of the table, and distance strategy, which is a way to compare embeddings.

Now we are ready to use vector store for searching documents that match the user query. Thanks for watching.