In this demo, let us look at the chat models available in the OCI Generative AI service. So I'm logged into my Oracle Cloud account. You can see that right now, I'm in the Germany central Frankfurt region. And the way I can access the generative AI service is by clicking on this burger menu on the left-hand side. And right here, there is Analytics & AI, so I'll click on that. And then within Analytics & AI, there are a bunch of AI services, and generative AI appears at the very top.

So let me click on Generative AI, and this will bring me to the landing page of the generative AI service. Right here, I can see the playground, the chat models, dedicated AI clusters, et cetera. So I'm interested in the chat models, so I'll click on chat. And now here, this gives me an interface in the playground where I can interact with the chat models.

So the first thing I can see here are the various chat models available. So I can see Cohere Command R plus. I can see Cohere Command R-16K model. And I can also see the Llama 3.1 family-- 405 billion model, 70 billion models. If I want to get more details, I can click on View more details, and I can see more details behind each of these models.

So here, what I'm going to do now is I'm going to show you four use cases around chat, around data extraction, around text generation, and text classification. So let me start with a typical scenario around chat. So I can come here, and now I can start chatting with these models. I'll pick Command R plus model here just because it's a much more powerful model and has longer context window.

So I can come here, and I can type a message. I can say something like, I'm an instructor with Oracle Cloud. Can you generate an outline for a course on Oracle Cloud Infrastructure Generative AI service, the course which we are in right now. And I'll click on Submit. And what this chat model will do now is it will give me an outline on what this course should look like. And it's a typical chat scenario, so it gives me a list of lessons. And here, because my output token was limited to 600, you can see that it kind of stopped generating beyond the 600 tokens.

But now I can come here, and I can interact with the output. So I could say something like, expand on number two above. And what it will do is it will talk a little bit more about getting started with OCI Generative AI service. And it basically takes that particular module and it expands on that module. And it says that in that particular module, I can cover these 10 lessons around how to get started, understanding the service, navigating the console, creating account, pricing, licensing, et cetera. So it's a fairly good outline for what this course should be.

And now I can go back and forth. I can interact. So this is a typical chat scenario. And you could chat with the model as much as you like. Depending on the output you're getting, you can change the prompt, and you will get a different response. So this is the first example of how you can interact with the model, how you can chat with the model.

Let me clear this chat. Now, what I can also do is I'll show you how you can change some of these parameters. So let's make temperature zero. And now I can give another prompt, something like, write a particular-- write a short poem about Cohere Embed model, focusing on the recent Embed V3 launch, in the style of Rudyard Kipling. And if you submit it now, you will see that the model starts generating an output.

And right now, I have given the temperature as zero. So let me open another window here and do the same thing, but instead change the temperature to something like one and keep all the other parameters the same. And now you would see that when I hit Submit, it will generate an output which will look different than the first output here. So this one is more deterministic model because I've given the temperature as zero. This one is more probabilistic. It's giving me more random output.

Now I can come here, and I could also change the preamble. I could say, answer in a pirate tone. And when I do that and I submit the chat again, now you can see that the output which is coming is kind of in a different tone compared to what was shown earlier. So this is an example where you can change some of these parameters-- temperature, preamble, top P, top K, et cetera-- to get a different output from the model.

Well, let me walk you through a different example, which is around data extraction. So if I give something like this as a prompt, saying that extract the entities mentioned in the text below. And these are taken from Wikipedia about NVIDIA. And if I click Submit here, you can see that what this chat model is doing is taking this particular paragraph and it is extracting the themes and the keywords from this particular paragraph. And you can imagine, if you have a longer document which is running into hundreds of pages or thousands of pages, something like this could be really useful.

Final example here is around text classification. So what I can do here is I can write a text classifier saying that I have a message like, I can't stand waiting in long lines at the grocery store, and the sentiment is negative. And I can give a bunch of these messages like these. And then I can give a particular message. And I would ask the model to specify or give the sentiment for that particular message. And it says learning a new language has been challenging but rewarding. So this is kind of aspect-based sentiment analysis. And it says that even though the effort is challenging, but the result is rewarding, so the overall sentiment is positive.

So these are some of the things you can do with the chat models. You can, of course, chat with the models. You can extract information from the model, information retrieval. You can generate text with the model. And you can also do things like text classification with the model. And there are various use cases. I'm just showing you a few very common use cases you can perform with the chat models available in the OCI Generative AI service. I hope you found this demo useful. Thanks for your time.